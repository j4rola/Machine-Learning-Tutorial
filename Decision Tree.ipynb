{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# In this lesson we will learn how to write a simple machine learning algorithm called a decision tree.\n",
    "# This algorithm will predict a persons gender based on their height and weight. \n",
    "# The first thing we do is import scikitlearn (above). \n",
    "# We then import the decision tree from sckikitlearn and train it with sample data. \n",
    "# 'Features' are characteristics of datapoints, while 'labels' are an exclusive name assigned to a datapoint. \n",
    "# By assigning the labels to the features using the code below we train the decision tree to predict a label\n",
    "# based on only a set of features. The man, for example, who is 170 lbs and 1.72 meters tall is not included in the \n",
    "# training data but is nevertheless correctly identified as male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male'], dtype='<U6')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "features = [[130, 1.75], [150, 1.7], [127, 1.57], [160, 1.77], [97, 1.57], [127, 1.6]]\n",
    "labels = ['male', 'male', 'female', 'male', 'female', 'female']\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(features, labels)\n",
    "clf.predict([[170, 1.72]])\n",
    "from scikitlearn.metrics import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees operate by asking yes or no questions based on your features. Therefore, the features you pick to \n",
    "# train your tree are very important in making an accurate prediction. If your classification is binary, \n",
    "# (into two groups) your features should be good distinguishers between those two things. Including features that \n",
    "# distinguish the two things can be detrimental to your tree's accuracy because it then relies on useless data, at\n",
    "# least in part, to make it's decision. \n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try something similar with more complicated data. \n",
    "# sklearn comes with several example datasets built in. We can load one using the code below. The .target function\n",
    "# allows us to see how many kinds of things we are dealing with. In this case, each of the three species \n",
    "# of flower has its own number. \n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris() \n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets think of our decision tree as a function for a moment, and set the data itself equal to x (the input), and\n",
    "# the label (output) to y. So, what goes into our function is a group of features and what comes out is the kind of \n",
    "# of flower, represented by a 0, 1, or 2. \n",
    "\n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the purpose of training decision trees there is a great utility within scikitlearn called train_test_split.\n",
    "# This utility splits data into training data and testing data. Training data is used to teach the computer to \n",
    "# recognize patterns. Testing data is used to determine how well the computer has learned. In the above example, the \n",
    "# original heights and weights assigned to the features variable are the training data. The new height and weight\n",
    "# (170 lbs, 1.72 m) that is introduced to the algorithm is the testing data. The train_test_split utility divides data\n",
    "# into training and testing data in whatever ratio we specify. \n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .5) \n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "redwood = tree.DecisionTreeClassifier()\n",
    "redwood.fit(x_train, y_train)\n",
    "xt = redwood.predict(x_test)\n",
    "\n",
    "# The code below runs a test that checks the test data against the training data to how accurate our algorithm is. \n",
    "# This particular algorithm is 96% accurate. Because chance is a still a factor in the accuracy of the algorithm, \n",
    "# we sometimes get different results from our test, as shown in the cell below. \n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_test, xt) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, xt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see here exactly where the algorithm went astray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 1, 0, 1, 2, 0, 2, 0, 1, 2, 0, 2, 1, 0, 1, 2, 1, 1, 1,\n",
       "       1, 0, 1, 0, 2, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 0, 2, 2, 2, 2, 2, 1,\n",
       "       0, 0, 1, 2, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 2, 2, 1, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 1, 0, 1, 2, 0, 2, 0, 2, 2, 0, 2, 1, 0, 1, 2, 1, 2, 2,\n",
       "       1, 0, 1, 0, 2, 1, 1, 2, 1, 2, 2, 1, 0, 0, 1, 0, 2, 1, 2, 2, 2, 1,\n",
       "       0, 0, 1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 2, 2, 0,\n",
       "       0, 2, 2, 1, 0, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
